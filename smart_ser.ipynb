{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mona1811k/Anomaly/blob/main/smart_ser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-12-09T06:59:28.820295Z",
          "iopub.status.busy": "2024-12-09T06:59:28.819919Z",
          "iopub.status.idle": "2024-12-09T06:59:40.013765Z",
          "shell.execute_reply": "2024-12-09T06:59:40.013061Z",
          "shell.execute_reply.started": "2024-12-09T06:59:28.820260Z"
        },
        "trusted": true,
        "id": "420iFavy0d59"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output,Video\n",
        "import keras\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T06:59:40.015694Z",
          "iopub.status.busy": "2024-12-09T06:59:40.015231Z",
          "iopub.status.idle": "2024-12-09T06:59:40.019619Z",
          "shell.execute_reply": "2024-12-09T06:59:40.018728Z",
          "shell.execute_reply.started": "2024-12-09T06:59:40.015667Z"
        },
        "trusted": true,
        "id": "JHsTt16m0d5-"
      },
      "outputs": [],
      "source": [
        "scvd_train_dir = '/kaggle/input/smartcity-cctv-violence-detection-dataset-scvd/SCVD/SCVD_converted_sec_split/Train'\n",
        "scvd_test_dir = '/kaggle/input/smartcity-cctv-violence-detection-dataset-scvd/SCVD/SCVD_converted_sec_split/Test'\n",
        "scvd_classes = ['Normal', 'Violence','Weaponized']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:50.895042Z",
          "iopub.status.busy": "2024-12-09T07:01:50.894138Z",
          "iopub.status.idle": "2024-12-09T07:01:50.898844Z",
          "shell.execute_reply": "2024-12-09T07:01:50.898046Z",
          "shell.execute_reply.started": "2024-12-09T07:01:50.895012Z"
        },
        "trusted": true,
        "id": "xyM-p2gy0d5-"
      },
      "outputs": [],
      "source": [
        "# Define the base directory and categories\n",
        "base_dir = '/kaggle/input/smartcity-cctv-violence-detection-dataset-scvd/SCVD/SCVD_converted_sec_split/Train'\n",
        "categories = ['Normal', 'Violence', 'Weaponized']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:51.660903Z",
          "iopub.status.busy": "2024-12-09T07:01:51.660566Z",
          "iopub.status.idle": "2024-12-09T07:01:51.829132Z",
          "shell.execute_reply": "2024-12-09T07:01:51.828033Z",
          "shell.execute_reply.started": "2024-12-09T07:01:51.660874Z"
        },
        "trusted": true,
        "id": "cbFj3uOD0d5-",
        "outputId": "0be1f17c-85d2-4f4c-ab92-59e34180b82e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video counts per category:\n",
            "Normal: 872 videos\n",
            "Violence: 970 videos\n",
            "Weaponized: 832 videos\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Function to count videos in each category\n",
        "def count_videos(base_dir, categories):\n",
        "    video_count = {}\n",
        "\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(base_dir, category)\n",
        "\n",
        "        if not os.path.exists(category_path):\n",
        "            print(f\"Directory for category '{category}' not found.\")\n",
        "            video_count[category] = 0\n",
        "            continue\n",
        "\n",
        "        # List all video files in the category directory\n",
        "        video_files = [f for f in os.listdir(category_path) if f.endswith(('.mp4', '.avi', '.mkv'))]\n",
        "        video_count[category] = len(video_files)\n",
        "\n",
        "    return video_count\n",
        "\n",
        "# Call the function and print the counts\n",
        "video_counts = count_videos(base_dir, categories)\n",
        "\n",
        "print(\"Video counts per category:\")\n",
        "for category, count in video_counts.items():\n",
        "    print(f\"{category}: {count} videos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:52.973635Z",
          "iopub.status.busy": "2024-12-09T07:01:52.973291Z",
          "iopub.status.idle": "2024-12-09T07:01:52.978011Z",
          "shell.execute_reply": "2024-12-09T07:01:52.976987Z",
          "shell.execute_reply.started": "2024-12-09T07:01:52.973608Z"
        },
        "trusted": true,
        "id": "eyPE0-wN0d5_"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:53.774277Z",
          "iopub.status.busy": "2024-12-09T07:01:53.773923Z",
          "iopub.status.idle": "2024-12-09T07:01:53.778712Z",
          "shell.execute_reply": "2024-12-09T07:01:53.777795Z",
          "shell.execute_reply.started": "2024-12-09T07:01:53.774247Z"
        },
        "trusted": true,
        "id": "B2DVRYQv0d5_"
      },
      "outputs": [],
      "source": [
        "# Define the label mapping\n",
        "label_mapping = {\"Normal\": 0, \"Violence\": 1, \"Weaponized\": 2}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:54.360726Z",
          "iopub.status.busy": "2024-12-09T07:01:54.360388Z",
          "iopub.status.idle": "2024-12-09T07:01:54.367015Z",
          "shell.execute_reply": "2024-12-09T07:01:54.366192Z",
          "shell.execute_reply.started": "2024-12-09T07:01:54.360698Z"
        },
        "trusted": true,
        "id": "n154VQUz0d5_"
      },
      "outputs": [],
      "source": [
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:55.533764Z",
          "iopub.status.busy": "2024-12-09T07:01:55.533430Z",
          "iopub.status.idle": "2024-12-09T07:02:00.882569Z",
          "shell.execute_reply": "2024-12-09T07:02:00.881832Z",
          "shell.execute_reply.started": "2024-12-09T07:01:55.533736Z"
        },
        "trusted": true,
        "id": "pfP9Q4tc0d5_",
        "outputId": "6d8330b5-acff-41d2-d88a-8823b5f47b9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:02:00.884981Z",
          "iopub.status.busy": "2024-12-09T07:02:00.884346Z",
          "iopub.status.idle": "2024-12-09T07:02:00.892642Z",
          "shell.execute_reply": "2024-12-09T07:02:00.891640Z",
          "shell.execute_reply.started": "2024-12-09T07:02:00.884939Z"
        },
        "trusted": true,
        "id": "838gzt-p0d5_"
      },
      "outputs": [],
      "source": [
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"original_path\"].values  # Use the 'original_path' column\n",
        "    labels = df[\"label\"].map(label_mapping).values  # Assuming label_mapping is defined\n",
        "\n",
        "    # Initialize placeholders for masks and features\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "    frame_features = np.zeros(\n",
        "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # For each video\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension\n",
        "        frames = load_video(path)  # Use the full path directly\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        # Initialize placeholders for the current video's masks and features\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(\n",
        "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        # Extract features from the frames of the current video\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "                    batch[None, j, :]\n",
        "                )\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        # Store features and masks for the current video\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:02:00.894602Z",
          "iopub.status.busy": "2024-12-09T07:02:00.893998Z",
          "iopub.status.idle": "2024-12-09T07:02:01.330702Z",
          "shell.execute_reply": "2024-12-09T07:02:01.329733Z",
          "shell.execute_reply.started": "2024-12-09T07:02:00.894565Z"
        },
        "trusted": true,
        "id": "EODQ7P9M0d6A",
        "outputId": "96abfbdb-3354-4120-c57b-9f11feea9f65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample of train_sample_metadata:\n",
            "                                       original_path   label\n",
            "0  /kaggle/input/smartcity-cctv-violence-detectio...  Normal\n",
            "1  /kaggle/input/smartcity-cctv-violence-detectio...  Normal\n",
            "2  /kaggle/input/smartcity-cctv-violence-detectio...  Normal\n",
            "3  /kaggle/input/smartcity-cctv-violence-detectio...  Normal\n",
            "4  /kaggle/input/smartcity-cctv-violence-detectio...  Normal\n",
            "Train and Test set shapes:\n",
            "(2406, 2) (268, 2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Base directory for the dataset\n",
        "base_dir = '/kaggle/input/smartcity-cctv-violence-detection-dataset-scvd/SCVD/SCVD_converted_sec_split/Train'\n",
        "\n",
        "# Define the class labels\n",
        "categories = ['Normal', 'Violence', 'Weaponized']\n",
        "\n",
        "# Initialize a list to store metadata\n",
        "metadata = []\n",
        "\n",
        "# Traverse through each category\n",
        "for category in categories:\n",
        "    category_path = os.path.join(base_dir, category)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Category directory '{category}' not found!\")\n",
        "        continue\n",
        "\n",
        "    # List all video files in the category directory\n",
        "    video_files = [f for f in os.listdir(category_path) if f.endswith(('.mp4', '.avi', '.mkv'))]\n",
        "    for video_file in video_files:\n",
        "        # Create full path to the video\n",
        "        video_path = os.path.join(category_path, video_file)\n",
        "        # Append metadata\n",
        "        metadata.append({'original_path': video_path, 'label': category})\n",
        "\n",
        "# Create a DataFrame from the metadata\n",
        "train_sample_metadata = pd.DataFrame(metadata)\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"Sample of train_sample_metadata:\")\n",
        "print(train_sample_metadata.head())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Train_set, Test_set = train_test_split(\n",
        "    train_sample_metadata,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=train_sample_metadata['label']\n",
        ")\n",
        "\n",
        "print(\"Train and Test set shapes:\")\n",
        "print(Train_set.shape, Test_set.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "LEw_xAts0d6A"
      },
      "outputs": [],
      "source": [
        "train_data, train_labels = prepare_all_videos(Train_set, \"train\")\n",
        "test_data, test_labels = prepare_all_videos(Test_set, \"test\")\n",
        "\n",
        "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {train_data[1].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T08:12:14.952592Z",
          "iopub.status.busy": "2024-12-09T08:12:14.952227Z",
          "iopub.status.idle": "2024-12-09T08:12:14.957221Z",
          "shell.execute_reply": "2024-12-09T08:12:14.956460Z",
          "shell.execute_reply.started": "2024-12-09T08:12:14.952560Z"
        },
        "trusted": true,
        "id": "yKJnhAj-0d6A",
        "outputId": "3e7d78e7-4285-4b30-ca91-abf302bcf560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frame features in train set: (2406, 20, 2048)\n",
            "Frame masks in train set: (2406, 20)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {train_data[1].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T08:11:52.293326Z",
          "iopub.status.busy": "2024-12-09T08:11:52.292968Z",
          "iopub.status.idle": "2024-12-09T08:11:52.358509Z",
          "shell.execute_reply": "2024-12-09T08:11:52.357715Z",
          "shell.execute_reply.started": "2024-12-09T08:11:52.293294Z"
        },
        "trusted": true,
        "id": "_rDdmXCC0d6A",
        "outputId": "8d510b26-2388-470f-abcf-5d7951839fd2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">99,168</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span> │ gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m2048\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │     \u001b[38;5;34m99,168\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m624\u001b[0m │ gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ gru_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │         \u001b[38;5;34m72\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m27\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,891</span> (390.20 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,891\u001b[0m (390.20 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,891</span> (390.20 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,891\u001b[0m (390.20 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "# Refer to the following tutorial to understand the significance of using `mask`:\n",
        "# https://keras.io/api/layers/recurrent_layers/gru/\n",
        "x = keras.layers.GRU(16, return_sequences=True)(\n",
        "    frame_features_input, mask=mask_input\n",
        ")\n",
        "x = keras.layers.GRU(8)(x)\n",
        "x = keras.layers.Dropout(0.4)(x)\n",
        "x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "output = keras.layers.Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T08:44:20.898163Z",
          "iopub.status.busy": "2024-12-09T08:44:20.897421Z",
          "iopub.status.idle": "2024-12-09T08:44:20.931993Z",
          "shell.execute_reply": "2024-12-09T08:44:20.931325Z",
          "shell.execute_reply.started": "2024-12-09T08:44:20.898131Z"
        },
        "trusted": true,
        "id": "rV0UPXT10d6B"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T08:44:22.526217Z",
          "iopub.status.busy": "2024-12-09T08:44:22.525834Z",
          "iopub.status.idle": "2024-12-09T08:44:22.583619Z",
          "shell.execute_reply": "2024-12-09T08:44:22.582970Z",
          "shell.execute_reply.started": "2024-12-09T08:44:22.526157Z"
        },
        "trusted": true,
        "id": "MdBJ0CQ70d6B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "n5odZ0_E0d6B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "23a5Y_R_0d6B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 2151340,
          "sourceId": 7312675,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30805,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}